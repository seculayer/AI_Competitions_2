{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citations & Resources\n",
    "Used most of the idea from this kernal \n",
    "https://www.kaggle.com/xhlulu/aptos-2019-densenet-keras-starter\n",
    "Data used: converted 224x224 sized image from the kernal \n",
    "\n",
    "https://www.kaggle.com/xhlulu/recursion-2019-load-resize-and-save-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['recursion-cellular-image-classification', 'recursion-complete', 'densenet-keras']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras.applications.densenet import preprocess_input\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score\n",
    "from keras.utils import Sequence\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "WORKERS = 2\n",
    "CHANNEL = 3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 224\n",
    "NUM_CLASSES = 1108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f543e3edda0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../input/recursion-complete/new_train.csv')\n",
    "df_test = pd.read_csv('../input/recursion-complete/new_test.csv')\n",
    "\n",
    "x = df_train['filename']\n",
    "y = df_train['sirna']\n",
    "\n",
    "x, y = shuffle(x, y, random_state=10)\n",
    "y.hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62075,)\n",
      "(62075, 1108)\n",
      "(10955,)\n",
      "(10955, 1108)\n"
     ]
    }
   ],
   "source": [
    "train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.15,\n",
    "                                                      stratify=y, random_state=10)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(valid_x.shape)\n",
    "print(valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/aleju/imgaug\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "seq = iaa.Sequential([\n",
    "    sometimes(\n",
    "        iaa.OneOf([\n",
    "            iaa.Add((-10, 10), per_channel=0.5),\n",
    "            iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
    "            iaa.ContrastNormalization((0.9, 1.1), per_channel=0.5)\n",
    "        ])\n",
    "    ),\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Crop(percent=(0, 0.1)),\n",
    "    # iaa.Flipud(0.5)\n",
    "],random_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Generator(Sequence):\n",
    "\n",
    "    def __init__(self, image_filenames, labels,\n",
    "                 batch_size, is_train=True,\n",
    "                 mix=False, augment=False):\n",
    "        self.image_filenames, self.labels = image_filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.is_train = is_train\n",
    "        self.is_augment = augment\n",
    "        if(self.is_train):\n",
    "            self.on_epoch_end()\n",
    "        self.is_mix = mix\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        if(self.is_train):\n",
    "            return self.train_generate(batch_x, batch_y)\n",
    "        return self.valid_generate(batch_x, batch_y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if(self.is_train):\n",
    "            self.image_filenames, self.labels = shuffle(self.image_filenames, self.labels)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    def mix_up(self, x, y):\n",
    "        lam = np.random.beta(0.2, 0.4)\n",
    "        ori_index = np.arange(int(len(x)))\n",
    "        index_array = np.arange(int(len(x)))\n",
    "        np.random.shuffle(index_array)        \n",
    "        \n",
    "        mixed_x = lam * x[ori_index] + (1 - lam) * x[index_array]\n",
    "        mixed_y = lam * y[ori_index] + (1 - lam) * y[index_array]\n",
    "        \n",
    "        return mixed_x, mixed_y\n",
    "\n",
    "    def train_generate(self, batch_x, batch_y):\n",
    "        batch_images = []\n",
    "        for (sample, label) in zip(batch_x, batch_y):\n",
    "\n",
    "            img = cv2.imread('../input/recursion-complete/train/train/'+sample)\n",
    "#             try:\n",
    "#                 img.shape\n",
    "#                 print(\"checked for shape\".format(img.shape))\n",
    "#             except AttributeError:\n",
    "#                 print(\"shape not found\")\n",
    "#             img = cv2.resize(img, (SIZE, SIZE))\n",
    "            if(self.is_augment):\n",
    "                img = seq.augment_image(img)\n",
    "            batch_images.append(img)\n",
    "        batch_images = np.array(batch_images, np.float32)/255\n",
    "#         print(batch_images.shape)\n",
    "        batch_y = np.array(batch_y, np.float32)\n",
    "        if(self.is_mix):\n",
    "            batch_images, batch_y = self.mix_up(batch_images, batch_y)\n",
    "        return batch_images, batch_y\n",
    "\n",
    "    def valid_generate(self, batch_x, batch_y):\n",
    "        batch_images = []\n",
    "        for (sample, label) in zip(batch_x, batch_y):\n",
    "            img = cv2.imread('../input/recursion-complete/train/train/'+sample)\n",
    "#             img = cv2.resize(img, (SIZE, SIZE))\n",
    "            batch_images.append(img)\n",
    "        batch_images = np.array(batch_images, np.float32)/255\n",
    "        \n",
    "        batch_y = np.array(batch_y, np.float32)\n",
    "        return batch_images, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D)\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras.optimizers import Nadam\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape,n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = DenseNet121(include_top=False,\n",
    "                   weights=None,\n",
    "                   input_tensor=input_tensor)\n",
    "    base_model.load_weights('../input/densenet-keras/DenseNet-BC-121-32-no-top.h5')\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "#     x = Dropout(0.1)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    " \n",
    "    final_output = Dense(n_out, activation='softmax', name='final_output')(x)\n",
    "    model = Model(input_tensor, final_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
    "                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n",
    "\n",
    "epochs = 10; batch_size = 8\n",
    "checkpoint = ModelCheckpoint('../working/Densenet121.h5', monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, \n",
    "                                   verbose=1, mode='auto', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=15)\n",
    "\n",
    "csv_logger = CSVLogger(filename='../working/training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "# callbacks_list = [checkpoint, csv_logger, reduceLROnPlat, early]\n",
    "\n",
    "train_generator = My_Generator(train_x, train_y, 128, is_train=True)\n",
    "train_mixup = My_Generator(train_x, train_y, batch_size, is_train=True, mix=False, augment=True)\n",
    "valid_generator = My_Generator(valid_x, valid_y, batch_size, is_train=False)\n",
    "\n",
    "model = create_model(input_shape=(SIZE,SIZE,3),n_out=NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa_loss(y_true, y_pred, y_pow=2, eps=1e-12, N=1108, bsize=8, name='kappa'):\n",
    "    \"\"\"A continuous differentiable approximation of discrete kappa loss.\n",
    "        Args:\n",
    "            y_pred: 2D tensor or array, [batch_size, num_classes]\n",
    "            y_true: 2D tensor or array,[batch_size, num_classes]\n",
    "            y_pow: int,  e.g. y_pow=2\n",
    "            N: typically num_classes of the model\n",
    "            bsize: batch_size of the training or validation ops\n",
    "            eps: a float, prevents divide by zero\n",
    "            name: Optional scope/name for op_scope.\n",
    "        Returns:\n",
    "            A tensor with the kappa loss.\"\"\"\n",
    "\n",
    "    with tf.name_scope(name):\n",
    "        y_true = tf.to_float(y_true)\n",
    "        repeat_op = tf.to_float(tf.tile(tf.reshape(tf.range(0, N), [N, 1]), [1, N]))\n",
    "        repeat_op_sq = tf.square((repeat_op - tf.transpose(repeat_op)))\n",
    "        weights = repeat_op_sq / tf.to_float((N - 1) ** 2)\n",
    "    \n",
    "        pred_ = y_pred ** y_pow\n",
    "        try:\n",
    "            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [-1, 1]))\n",
    "        except Exception:\n",
    "            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [bsize, 1]))\n",
    "    \n",
    "        hist_rater_a = tf.reduce_sum(pred_norm, 0)\n",
    "        hist_rater_b = tf.reduce_sum(y_true, 0)\n",
    "    \n",
    "        conf_mat = tf.matmul(tf.transpose(pred_norm), y_true)\n",
    "    \n",
    "        nom = tf.reduce_sum(weights * conf_mat)\n",
    "        denom = tf.reduce_sum(weights * tf.matmul(\n",
    "            tf.reshape(hist_rater_a, [N, 1]), tf.reshape(hist_rater_b, [1, N])) /\n",
    "                              tf.to_float(bsize))\n",
    "    \n",
    "        return nom*0.5 / (denom + eps) + categorical_crossentropy(y_true, y_pred)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "485/485 [==============================] - 225s 463ms/step - loss: 6.7310\n",
      "Epoch 2/30\n",
      "485/485 [==============================] - 192s 395ms/step - loss: 6.0755\n",
      "Epoch 3/30\n",
      "485/485 [==============================] - 196s 405ms/step - loss: 5.6511\n",
      "Epoch 4/30\n",
      "485/485 [==============================] - 194s 400ms/step - loss: 5.3228\n",
      "Epoch 5/30\n",
      "485/485 [==============================] - 193s 398ms/step - loss: 5.0437\n",
      "Epoch 6/30\n",
      "485/485 [==============================] - 194s 400ms/step - loss: 4.8032\n",
      "Epoch 7/30\n",
      "485/485 [==============================] - 191s 394ms/step - loss: 4.6010\n",
      "Epoch 8/30\n",
      "485/485 [==============================] - 193s 397ms/step - loss: 4.4244\n",
      "Epoch 9/30\n",
      "485/485 [==============================] - 191s 395ms/step - loss: 4.2595\n",
      "Epoch 10/30\n",
      "485/485 [==============================] - 190s 391ms/step - loss: 4.1006\n",
      "Epoch 11/30\n",
      "485/485 [==============================] - 192s 396ms/step - loss: 3.9547\n",
      "Epoch 12/30\n",
      "485/485 [==============================] - 193s 399ms/step - loss: 3.8183\n",
      "Epoch 13/30\n",
      "124/485 [======>.......................] - ETA: 2:25 - loss: 3.5775"
     ]
    }
   ],
   "source": [
    "# warm up model\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i in range(-3,0):\n",
    "    model.layers[i].trainable = True\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Nadam(1e-3))\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(float(len(train_y)) / float(128)),\n",
    "    epochs=30,\n",
    "    workers=WORKERS, use_multiprocessing=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7760/7760 [==============================] - 1410s 182ms/step - loss: 5.3574 - acc: 0.0778 - val_loss: 5.6786 - val_acc: 0.0869\n",
      "Epoch 2/10\n",
      "4736/7760 [=================>............] - ETA: 8:34 - loss: 4.6768 - acc: 0.1360"
     ]
    }
   ],
   "source": [
    "# train all layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "callbacks_list = [csv_logger, reduceLROnPlat]\n",
    "model.compile(optimizer=Nadam(1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    train_mixup,\n",
    "    steps_per_epoch=np.ceil(float(len(train_x)) / float(batch_size)),\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=np.ceil(float(len(valid_x)) / float(batch_size)),\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    workers=2, use_multiprocessing=True,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"../working/Densenet121.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../input/recursion-cellular-image-classification/sample_submission.csv')\n",
    "model.load_weights('../working/Densenet121.h5')\n",
    "predicted = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19897it [07:13, 45.86it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, name in tqdm(enumerate(submit['id_code'])):\n",
    "    path = os.path.join('../input/recursion-complete/test/test/', name+'_s1.jpeg')\n",
    "    image = cv2.imread(path)\n",
    "#     image = cv2.resize(image, (SIZE, SIZE))\n",
    "    score_predict = model.predict((image[np.newaxis])/255)\n",
    "    label_predict = np.argmax(score_predict)\n",
    "    predicted.append(str(label_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>sirna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HEPG2-08_1_B03</td>\n",
       "      <td>1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEPG2-08_1_B04</td>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEPG2-08_1_B05</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEPG2-08_1_B06</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HEPG2-08_1_B07</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_code sirna\n",
       "0  HEPG2-08_1_B03  1042\n",
       "1  HEPG2-08_1_B04  1006\n",
       "2  HEPG2-08_1_B05    57\n",
       "3  HEPG2-08_1_B06    94\n",
       "4  HEPG2-08_1_B07   254"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sirna'] = predicted\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "submit.head()\n",
    "# submission['sirna'] = preds.astype(int)\n",
    "# submission.to_csv('submission.csv', index=False, columns=['id_code','sirna'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
