# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A9g9AgKYPfLbQ1-J9uODLYQb9YLeL2qv
"""

# Pandas and numpy for data manipulation
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
from patsy import dmatrices
from statsmodels.stats.outliers_influence import variance_inflation_factor
from pandas import DataFrame
data = pd.read_csv('drive/MyDrive/loan-default-prediction/train_v2.csv.zip')

data.shape

data.head()

data.info()

data.describe()

data.isnull().sum().sum()

mis_val=data.isnull().sum()

mis_val_percent = 100 * data.isnull().sum() / len(data)

def tableformissingvalues(df):
 
        missingvalues = df.isnull().sum()
        percent = 100 * df.isnull().sum() / len(df)
        table = pd.concat([missingvalues,percent], axis=1)
        tablerenamed = table.rename(
            columns = {0 : 'Missing Values', 1 : 'Percentage'})

        return tablerenamed

tableformissingvalues(data).head(50)


data.fillna(data.mean(), inplace=True)
data.shape

data['Classifier'] = [0 if x ==0 else 1 for x in data['loss']]

data.head()
data.dropna(inplace=True)
data.shape
data.describe()

plt.figure(figsize=(5,5))
data['loss'].plot(kind='density')

data.info()

data.to_csv (r"/content/drive/MyDrive/loan-default-prediction/training-data.csv", index = False, header=True)
trainingdata = pd.read_csv("/content/drive/MyDrive/loan-default-prediction/training-data.csv",low_memory=False)

trainingdata.shape

plt.hist(trainingdata['Classifier'],color = 'yellow', edgecolor = 'black',  bins = int(100/5))

sns.countplot(x ='Classifier', data = trainingdata)

correlations_data = trainingdata.corr()['Classifier'].sort_values()

print(trainingdata['Classifier'])

plt.figure(figsize=(50,35))
#sns.heatmap(correlations_data,fmt='.1g',vmin=-1, vmax=1, center= 0)

print(correlations_data.head(15), '\n')

print(correlations_data.tail(15))

for i in trainingdata.columns:
    if len(set(trainingdata[i]))==1:
        trainingdata.drop(labels=[i], axis=1, inplace=True)

print(correlations_data.head(15), '\n')

print(correlations_data.tail(15))

trainingdata.shape


print("Data types and their frequency\n{}".format(trainingdata.dtypes.value_counts()))

trainingdata.select_dtypes(include=['object'])

for i in trainingdata.select_dtypes(include=['object']).columns:
    trainingdata.drop(labels=i, axis=1, inplace=True)

trainingdata.shape

zeroes = trainingdata[trainingdata['Classifier'] == 0] 
zeroes.shape

ones = trainingdata[trainingdata['Classifier'] == 1] 
ones.shape


frames=[zeroes,ones]

train=pd.concat(frames)
train.shape

Y1 = train['Classifier'] # dependent variable
X1 = train.drop('Classifier', axis=1)

vif  = [variance_inflation_factor(X1.values, i) for i in range(X1.shape[1])]

vif

VIF = DataFrame (vif,columns=['VIF Score'])

VIF["features"] = X1.columns
VIF.shape
VIF1 = VIF[VIF['VIF Score'] > 5.0] 
VIF1.shape
list1=list(VIF1['features']) 
list1
train.shape
train=train.drop(list1, axis = 1)
train.shape

from sklearn.model_selection import train_test_split

features = train.drop(columns=['Classifier','loss'])

targets = pd.DataFrame(train['Classifier'])

X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size = 0.2, random_state = 42)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

y_train = np.array(y_train).reshape((-1, ))
y_test = np.array(y_test).reshape((-1, ))

X_train
X_test
X_train.shape

print(y_train.shape)

testdata=pd.read_csv('drive/MyDrive/loan-default-prediction/test_v2.csv.zip')

testdata.shape

testdata.fillna(testdata.mean(), inplace=True) 

testdata.dropna()

testdata.isnull().sum().sum()


for i in testdata.columns:
    if len(set(testdata[i]))==1:
        testdata.drop(labels=[i], axis=1, inplace=True)

testdata.shape

print("Data types and their frequency\n{}".format(testdata.dtypes.value_counts()))

for i in testdata.select_dtypes(include=['object']).columns:
    testdata.drop(labels=i, axis=1, inplace=True)

testdata.shape

list2=list1
testdata=testdata.drop(list2, axis = 1)

testdata.shape

testdata.head()

train.head()

# arr = np.array(0,dtype=float)
# arr2 = np.array(0,dtype=float)
# #data = data.drop(columns=['Classifier','loss'])

# for i in data:
#   print(i)
#   #print(type(testdata[i]))
#   #print(type(testdata[i].values))
#   #print(testdata[i].values.shape)
#   arr=np.append(arr,testdata[i].values)

# print(arr.shape)
# print(arr[0:3])
# arr = np.delete(arr,0)
# print(arr[0:3])
# # for index in range(0, len(arr), 740):
# # 	arr2 = np.append(arr2,arr[index:index + 740])
# # print(arr2.shape)
# arr.resize(210944,155)

def crossvalidation(X_train, y_train, model):
    # Applying k-Fold Cross Validation
    from sklearn.model_selection import cross_val_score
    accuracies = cross_val_score(estimator = model, X = X_train, y = y_train, cv = 5)
    return accuracies.mean()


def trainmodel(model):
    
    model.fit(X_train, y_train)
    
    model_pred = model.predict(testdata)
    model_cross = crossvalidation(X_train, y_train, model)
    
    return model_cross

print(pred.sum())

# from sklearn.linear_model import LogisticRegression 
# model = LogisticRegression(solver= 'saga', class_weight='balanced',max_iter=500, random_state=1) 
# model.fit(X_train,y_train)
# pred= model.predict(testdata)

# print(pred)

# print('Logistic regression Performance on the test set: Cross Validation Score = %0.4f' % logistic_cross)

# print(pred.shape)
# sns.countplot(pred);
# print(pred.sum())

from xgboost import XGBClassifier
model = XGBClassifier(n_estimators = 400)
model.fit(X_train,y_train)
pred = model.predict(testdata)

print(pred.shape)
sns.countplot(pred);
print(pred.sum())

submission = pd.read_csv("/content/drive/MyDrive/loan-default-prediction/sampleSubmission.csv")
print(submission.shape)
submission['loss'] = pred

submission.head()

submission.to_csv("/content/drive/MyDrive/loan-default-prediction/submission1.csv", index=False)